# Generating NIR Images from RGB 

This project focuses on the task of generating Near-Infrared (NIR) images based on corresponding visible spectrum (RGB) images. 

## Problem Description and Task

Satellite and aerial images often contain information across various spectral bands. The NIR (Near-Infrared) channel is particularly important for analyzing vegetation, water bodies, and other aspects of the Earth's surface, as it provides information invisible in the standard RGB spectrum. However, not all sensors or datasets include an NIR channel, or it might be corrupted.

**The project task** is to develop and train a deep learning model capable of synthesizing a realistic NIR channel based on an existing RGB image. This will enhance data analysis capabilities where the NIR channel is missing or unavailable.



## Project Structure

## Dataset

The deepNIR subset of SEN12MS dataset was used for training the model. This dataset contains multispectral images from Sentinel-1 (SAR) and Sentinel-2 (optical, including RGB and NIR channels), along with other auxiliary data.

*   **DeepNIR ():** [SEN12MS - A Multi-Sensor Land Cover Classification Dataset](https://www.kaggle.com/datasets/enddl22/deepnir-nir-rgb-capsicum).
*   **Dataset Link (Original Publication):** [SEN12MS: A Curated Dataset of Paired SAR and Multi-Spectral Satellite Imagery for Deep Learning and Data Fusion](https://mediatum.ub.tum.de/1474000)

This project uses pairs of RGB (from Sentinel-2) and NIR (also from Sentinel-2) images. The data is organized into folders like `train_A` (RGB), `train_B` (NIR), `val_A`, `val_B`, etc.

## How to Run

1.  **Clone the repository:**
    ```bash
    git clone <your_repository_URL>
    cd <repository_name>
    ```
2.  **Install dependencies:**
    ```bash
    pip install torch torchvision torchaudio tqdm Pillow numpy tensorboard
    ```
    (Ensure you have a PyTorch version compatible with your hardware, e.g., with MPS support for Apple Silicon).
3.  **Prepare the dataset:**
    *   Download the SEN12MS dataset (or the part containing Sentinel-2 RGB and NIR channels).
    *   Organize the data according to the structure expected by the `RGBNIRPairedDataset` class (e.g., `path_to_dataset/train_A/`, `path_to_dataset/train_B/`).
    *   Update the `root_dir` parameter in the configuration dictionary within the `main_small.py` (or `main.py`) script.
4.  **Configure settings:**
    Open `main_small.py` (or `main.py`) and modify parameters in the `config` dictionary if needed (e.g., `batch_size`, `num_epochs`, `image_size`, model parameters, paths for logs and checkpoints).
5.  **Start training:**
    ```bash
    python RGB_to_NIR/main_<the model you want to train>.py
    ```
6.  **Monitor progress with TensorBoard:**
    In a new terminal window, navigate to the project's root folder and run:
    ```bash
    tensorboard --logdir=runs
    ```
    Open the provided URL (usually `http://localhost:6006/`) in your browser.

## Preliminary Results

Below are some early visual results from the Conditional WGAN-GP model. These results are preliminary, and the model requires further training to improve the quality and accuracy of the generated Near-Infrared (NIR) images.

The image shows:
*   **Top Row:** Input RGB images.
*   **Middle Row:** Real NIR images (Ground Truth).
*   **Bottom Row:** NIR images generated by the WGAN-GP model from the corresponding input RGB images.

![Evaluation Summary](evaluation_results/rgb_to_nir_small_v1_epoch10_imported_fix/evaluation_summary.png)

## Future Improvements (Possible)

*   Implement a validation loop and log image quality metrics (PSNR, SSIM) on the validation set.
*   More sophisticated data augmentation (if required).
*   Comparison with other architectures (e.g., Pix2PixHD, Diffusion Models).
*   Hyperparameter optimization.
